{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":103417,"databundleVersionId":12473839,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\ndf = pd.read_csv('/kaggle/input/mock-test-2-mse-2/train.csv')\ndf.head()\n\ndf.drop(columns=['id'], axis=1, inplace=True)\n\ndf\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\nLE = LabelEncoder()\n\ndf['Drug']=LE.fit_transform(df['Drug'])\ndf['Sex']=LE.fit_transform(df['Sex'])\ndf['Ascites']=LE.fit_transform(df['Ascites'])\ndf['Spiders']=LE.fit_transform(df['Spiders'])\ndf['Edema']=LE.fit_transform(df['Edema'])\ndf['Hepatomegaly']=LE.fit_transform(df['Hepatomegaly'])\n\ndf\n\ndf.info()\n\n# df.fillna(df.mean(), inplace=True, numeric_only=True)\n# df = df.fillna(df.mean(numeric_only=True))\n\n# Fill missing numeric values with column means\nnumeric_cols = df.select_dtypes(include=['number']).columns\ndf[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n\n\nx = df.drop('Status', axis=1)\ny = df['Status']\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n\n\nmodel = RandomForestClassifier(n_estimators=250, random_state=42, max_depth=None)\nmodel.fit(x_train, y_train)\n\ny_pred =model.predict(x_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n\n\n#confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(cm)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.show()\n\n\nprint(classification_report(y_test, y_pred))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n\n\n\n\ndf_test = pd.read_csv('/kaggle/input/mock-test-2-mse-2/test.csv')\ntest_id = df_test['id']\ndf_test.drop(columns=['id'], inplace=True)\ndf_test.head()\n\n\n\n\ndf_test['Drug']=LE.fit_transform(df_test['Drug'])\ndf_test['Sex']=LE.fit_transform(df_test['Sex'])\ndf_test['Ascites']=LE.fit_transform(df_test['Ascites'])\ndf_test['Spiders']=LE.fit_transform(df_test['Spiders'])\ndf_test['Edema']=LE.fit_transform(df_test['Edema'])\ndf_test['Hepatomegaly']=LE.fit_transform(df_test['Hepatomegaly'])\ndf_test\n\n\n\nnumeric_cols = df_test.select_dtypes(include=['number']).columns\ndf_test[numeric_cols] = df_test[numeric_cols].fillna(df_test[numeric_cols].mean())\n\n\n\nproba = model.predict_proba(df_test)\n# y_pred_test = model.predict(df_test)\n\n\n\nclass_labels = LE.classes_\n\n# # convert to csv\n# submission = pd.DataFrame({\n#     'id': id,\n#     'Exited': y_pred_test\n# })\n# submission.to_csv('submission.csv', index=False)\n\n# submission = pd.DataFrame({\n#     'id': id,   # or the list of ids you kept\n#     'Status': y_pred_test\n# })\n\n# submission.to_csv('Submission.csv', index=False)\nsubmission = pd.DataFrame({\n    \"id\": test_id,\n    f\"Status_{class_labels[0]}\": proba[:, 0],\n    f\"Status_{class_labels[1]}\": proba[:, 1],\n    f\"Status_{class_labels[2]}\": proba[:, 2],\n})\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#rrrr\n\n\nimport pandas as pd \nimport numpy as np  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\ndf_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\ndf_shuffled.head()\n\n# yaha x aur y define kario x mai sare features and y target y ki hi enciding hogi\n\n#Encoding  2 types ================================================================\nle = LabelEncoder()\nY_Encoded = le.fit_transform(y)\n#======================================================================================\ndf_encoded = pd.get_dummies(train_df, columns=['Gender', 'Geography'], drop_first=True, dtype=int)\ndf_encoded.info()\n#-======================================  ============================\n#Boxplot \n\nfor col in df.columns[:-1]:\n    plt.figure(figsize=(4, 6))\n    plt.boxplot(df[col].dropna())\n    plt.title(f\"Boxplot of {col}\")\n    plt.ylabel(col)\n    plt.show()\n\ncols_to_clip = [\n    'Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length',\n    'Convex_Area', 'Equiv_Diameter', 'Eccentricity', 'Solidity',\n    'Extent', 'Roundness', 'Aspect_Ration', 'Compactness'\n]\n\n\n#Remove Outlier ==============================\nfor col in cols_to_clip:\n    df[col] = df[col].clip(\n        lower=df[col].quantile(0.15),\n        upper=df[col].quantile(0.85)\n    )\n\n# use any 1 ================================\ndef remove_outliers_iqr(df, columns):\n    for col in columns:\n        Q1 = df[col].quantile(0.25)\n        Q3 = df[col].quantile(0.75)\n        IQR = Q3 - Q1\n        lower = Q1 - 1.5 * IQR\n        upper = Q3 + 1.5 * IQR\n        df = df[(df[col] >= lower) & (df[col] <= upper)]\n    return df\n\ndf_clean = remove_outliers_iqr(train_df, numeric_cols)\n#=====================================================================\n\nprint(f\"Before: {train_df.shape[0]} rows, After: {df_clean.shape[0]} rows\")\n\naccuracy = accuracy_score(Y_test, Y_predict)\nprint( 'Accuracy:', accuracy)\n\n#Hypertune\nmodel =  RandomForestClassifier()\nmodel.fit()\nparam_dist = {\n    'n_estimators': [100, 200, 300, 500, 800],\n    'max_depth': [None, 5, 10, 15, 20, 30],\n    'min_samples_split': [2, 5, 10, 15],\n    'min_samples_leaf': [1, 2, 4, 8],\n    'max_features': ['sqrt', 'log2', None],\n    'max_leaf_nodes': [None, 10, 20, 30, 50],\n    'bootstrap': [True, False],\n    'oob_score': [True, False]\n}\nrf = RandomForestClassifier(random_state=42)\nrandom_search = RandomizedSearchCV(\n    estimator=rf,\n    param_distributions=param_dist,\n    n_iter=50,            \n    cv=5,                \n    verbose=2,\n    random_state=42,\n    n_jobs=-1\n)\n\nrandom_search.fit(X_train, Y_train)\n\nbest_data = random_search.best_estimator_\nprint('Best hyperparameters:',  random_search.best_params_)\n\n#heatmap\n\ncorr=train_df.corr(numeric_only=True)\nplt.figure(figsize=(10,6))\nsns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title(\"Correlation Heatmap\", fontsize=14)\nplt.show()\n\n#pairplot \n\nsns.pairplot(train_df, vars=['CreditScore', 'Balance', 'Age', 'EstimatedSalary'],hue='Exited', diag_kind='kde', palette='coolwarm')\nplt.suptitle(\"Pairplot of Features w.r.t. Target (Exited)\", y=1.02, fontsize=14)\nplt.show()\n\n#scaling values \n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_res)\n\n#Confusion Matrix\n\nY_pred = best_data.predict(X_test)\ncm = confusion_matrix(Y_test, Y_pred)\nConfusionMatrixDisplay(confusion_matrix=cm).plot()\n\n#again accuracy\n\naccuracy = accuracy_score(Y_test, Y_pred)\nprint( 'Accuracy:', accuracy)\n\n#yeh aklag hai random se bhi ho jega ========================================================\n\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\nmodel = SVC()\n\nparam_grid = {\n    'C': [0.1, 1, 10, 100],\n    'kernel': ['linear', 'rbf', 'sigmoid'],\n    'gamma': ['scale', 'auto',0.01,0.1,1], \n    'coef0': [0.0, 0.1, 0.5]\n}\n\ngrid = GridSearchCV(\n    estimator=model,\n    param_grid=param_grid,\n    scoring='accuracy',    \n    cv=5,                  \n    verbose=2,\n    n_jobs=-1              \n)\n\ngrid.fit(X_train, y_train)\nprint(\"Best Parameters:\", grid.best_params_)\nprint(\"Best Cross-Validation Score:\", grid.best_score_)\nbest_model = grid.best_estimator_\ny_pred = best_model.predict(X_val)\n\n# The best parameters from above grid search are:\n# {'C': 10, 'coef0': 0.0, 'gamma': '0.1', 'kernel': 'rbf'}\n\n#=======================================================================================================\nfrom sklearn.svm import SVC\nmodel = SVC(kernel='rbf', C=10, gamma=0.1, coef0=0.0)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nroc_auc = roc_auc_score(y_val, y_pred)\nf1score = f1_score(y_val, y_pred)\nconf_matrix = confusion_matrix(y_val, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\nprint(f\"F1 Score: {f1score:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n#===================================================================================================================================\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nroc_auc = roc_auc_score(y_val, y_pred)\nf1score = f1_score(y_val, y_pred)\nconf_matrix = confusion_matrix(y_val, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\nprint(f\"F1 Score: {f1score:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n#=======================================================================================\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\n\nparam_grid = {\n    'n_estimators': [100, 200, 500],           \n    'max_depth': [None, 10, 20, 30],           \n    'min_samples_split': [2, 5, 10],           \n    'min_samples_leaf': [1, 2, 4],             \n    'max_features': ['sqrt', 'log2', None]\n}\n\ngrid = GridSearchCV(\n     estimator=model,\n     param_grid=param_grid,\n     scoring='accuracy',    \n     cv=3,                  \n     verbose=2,\n     n_jobs=-1\n)              \n\n\ngrid.fit(X_train, y_train)\nprint(\"Best Parameters:\", grid.best_params_)\nprint(\"Best Cross-Validation Score:\", grid.best_score_)\nbest_model = grid.best_estimator_\ny_pred = best_model.predict(X_val)\n\n# The best parameters from above grid search are:\n# {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n# now use this in main classifier\n\n# =================================================================================================\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, max_depth=30, min_samples_split=2, min_samples_leaf=1, max_features='sqrt')\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nroc_auc = roc_auc_score(y_val, y_pred)\nf1score = f1_score(y_val, y_pred)\nconf_matrix = confusion_matrix(y_val, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\nprint(f\"F1 Score: {f1score:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\nrf=RandomForestClassifier(n_estimators=100, max_depth=30, min_samples_split=2, min_samples_leaf=1, max_features='sqrt',oob_score=True, random_state=42)\nrf.fit(X_scaled, y_res)\n\n\nX_test_scaled = scaler.transform(X_test)\ny_pred=rf.predict_proba(X_test_scaled)\n\n# ======================================================================================================\n\n#yaha se last file banegi \n\nsub_df = pd.DataFrame({\n    'id': test_ids,\n    'Exited': y_pred[:,1]\n})\nsub_df.to_csv('submission_Bank.csv', index=False,float_format='%.6f')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#romeo julio\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, confusion_matrix,\n    ConfusionMatrixDisplay, RocCurveDisplay\n)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/test.csv\")\n\nprint(\"Train shape:\", train.shape)\nprint(\"Test shape:\", test.shape)\n\ndisplay(train.head())\n\nprint(\"\\n--- Data Info ---\")\nprint(train.info())\n\nprint(\"\\n--- Missing Values ---\")\ndisplay(train.isna().sum())\n\nprint(\"\\n--- Statistical Summary ---\")\ndisplay(train.describe(include='all').T)\n\nprint(\"\\n--- Target Distribution ---\")\ndisplay(train['Status'].value_counts())\n\n\n# Numeric columns\nnum_cols = train.select_dtypes(include=[np.number]).columns\n\nplt.figure(figsize=(12, 6))\ntrain[num_cols].boxplot(rot=90)\nplt.title(\"Outlier Analysis - Numeric Features (Boxplots)\")\nplt.tight_layout()\nplt.show()\n\n# IQR table\noutlier_rows = []\n\nfor col in num_cols:\n    q1 = train[col].quantile(0.25)\n    q3 = train[col].quantile(0.75)\n    iqr = q3 - q1\n    lower = q1 - 1.5 * iqr\n    upper = q3 + 1.5 * iqr\n    count = train[(train[col] < lower) | (train[col] > upper)].shape[0]\n    \n    outlier_rows.append({\n        \"Feature\": col,\n        \"Q1\": q1,\n        \"Q3\": q3,\n        \"IQR\": iqr,\n        \"Lower Bound\": lower,\n        \"Upper Bound\": upper,\n        \"Outlier Count\": count\n    })\n\noutlier_df = pd.DataFrame(outlier_rows).sort_values(\"Outlier Count\", ascending=False)\ndisplay(outlier_df)\n\n\n\n\n\n# Features and target\nX = train.drop(\"Status\", axis=1)\ny = train[\"Status\"]\n\n# Column types\ncat_cols = X.select_dtypes(include=[\"object\"]).columns\nnum_cols = X.select_dtypes(exclude=[\"object\"]).columns\n\nprint(\"Categorical:\", list(cat_cols))\nprint(\"Numerical:\", list(num_cols))\n\n# Preprocessor\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n        (\"cat\", Pipeline([\n            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n            (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n        ]), cat_cols)\n    ]\n)\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nmodel = Pipeline(steps=[\n    (\"prep\", preprocessor),\n    (\"clf\", RandomForestClassifier(\n        n_estimators=400,\n        random_state=42,\n        class_weight=\"balanced\"\n    ))\n])\n\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_val)\ny_proba = model.predict_proba(X_val)\nclasses = model.named_steps[\"clf\"].classes_\n\n\n\n\naccuracy  = accuracy_score(y_val, y_pred)\nprecision = precision_score(y_val, y_pred, average='weighted')\nrecall    = recall_score(y_val, y_pred, average='weighted')\nf1        = f1_score(y_val, y_pred, average='weighted')\n\n# Multi-class ROC-AUC\nfrom sklearn.preprocessing import label_binarize\ny_bin = label_binarize(y_val, classes=classes)\nroc_auc = roc_auc_score(y_bin, y_proba, multi_class='ovr', average=\"macro\")\n\nmetrics_df = pd.DataFrame({\n    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC-AUC\"],\n    \"Score\":  [accuracy, precision, recall, f1, roc_auc]\n})\n\nprint(\"\\n--- METRICS MATRIX ---\")\ndisplay(metrics_df)\n\n\n\n\ncm = confusion_matrix(y_val, y_pred, labels=classes)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n\nplt.figure(figsize=(5,5))\ndisp.plot(cmap=\"Blues\", colorbar=False)\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n\n\n\nplt.figure(figsize=(7,7))\n\nfor i, c in enumerate(classes):\n    RocCurveDisplay.from_predictions(\n        (y_val == c).astype(int),\n        y_proba[:, i],\n        name=f\"Class {c}\",\n        ax=plt.gca()\n    )\n\nplt.plot([0, 1], [0, 1], \"--\")\nplt.title(\"ROC Curves (One-vs-Rest)\")\nplt.show()\n\n\n\n\n\nclf = model.named_steps[\"clf\"]\n\n# Extract feature names\nohe = model.named_steps[\"prep\"].transformers_[1][1].named_steps[\"oh\"]\nohe_features = ohe.get_feature_names_out(cat_cols)\nall_features = np.concatenate([num_cols, ohe_features])\n\nimportances = clf.feature_importances_\nidx = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(8,6))\nplt.barh(all_features[idx][::-1], importances[idx][::-1])\nplt.title(\"Top 20 Feature Importances\")\nplt.xlabel(\"Importance\")\nplt.show()\n\n\nmodel.fit(X,y)\n\n\ntest_pred = model.predict_proba(test)\n\nsubmission = pd.DataFrame({\n    \"id\": test[\"id\"]\n})\n\nfor i, c in enumerate(classes):\n    submission[f\"Status_{c}\"] = test_pred[:, i]\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv saved!\")\ndisplay(submission.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#sior wala\n\n\nimport pandas as pd \nimport numpy as np  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n\ntrain_df=pd.read_csv('/Users/piyushagarwal/Documents/Python Files/Mock Dataset/train (1).csv')\ntest_df=pd.read_csv('/Users/piyushagarwal/Documents/Python Files/Mock Dataset/test (1).csv')\n\ntrain_df.info()\ntrain_df.head()\ntrain_df.drop(['id','CustomerId','Surname'],axis=1,inplace=True)\ntrain_df.head()\ntrain_df.isnull().sum()\ntrain_df.duplicated().sum()\n\n\n#sior wala\n\n\nimport pandas as pd \nimport numpy as np  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n\ntrain_df=pd.read_csv('/Users/piyushagarwal/Documents/Python Files/Mock Dataset/train (1).csv')\ntest_df=pd.read_csv('/Users/piyushagarwal/Documents/Python Files/Mock Dataset/test (1).csv')\n\ntrain_df.info()\ntrain_df.head()\ntrain_df.drop(['id','CustomerId','Surname'],axis=1,inplace=True)\ntrain_df.head()\ntrain_df.isnull().sum()\ntrain_df.duplicated().sum()\n lower = Q1 - 1.5 * IQR\n        upper = Q3 + 1.5 * IQR\n        df = df[(df[col] >= lower) & (df[col] <= upper)]\n    return df\n\ndf_clean = remove_outliers_iqr(train_df, numeric_cols)\n\nprint(f\"Before: {train_df.shape[0]} rows, After: {df_clean.shape[0]} rows\")\n\n\n\nfor col in numeric_cols:\n    plt.figure(figsize=(6, 4))\n    sns.boxplot(x=category_col, y=col, data=df_clean)\n    plt.title(f'Boxplot of {col} by {category_col}')\n    plt.xlabel(category_col)\n    plt.ylabel(col)\n    plt.tight_layout()\n    plt.show()\n\n\n\ncorr=train_df.corr(numeric_only=True)\nplt.figure(figsize=(10,6))\nsns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title(\"Correlation Heatmap\", fontsize=14)\nplt.show()\n\n\nsns.pairplot(train_df, vars=['CreditScore', 'Balance', 'Age', 'EstimatedSalary'],hue='Exited', diag_kind='kde', palette='coolwarm')\nplt.suptitle(\"Pairplot of Features w.r.t. Target (Exited)\", y=1.02, fontsize=14)\nplt.show()\n\n\n\nX = train_df.drop('Exited', axis=1)\ny = train_df['Exited']\n\n\n\nfrom imblearn.over_sampling import SMOTE\nunique, counts = np.unique(y, return_counts=True)\nmin_class_size = counts.min()\nk = min(5, max(1, min_class_size - 1))\n\nsmote = SMOTE(random_state=42, k_neighbors=k)\nX_res, y_res = smote.fit_resample(X, y)\n\nprint(\"Before:\", dict(zip(unique, counts)))\nprint(\"After:\", dict(zip(*np.unique(y_res, return_counts=True))))\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_res)\nX_train, X_val, y_train, y_val = train_test_split(X_scaled, y_res, test_size=0.2, random_state=42, stratify=y_res)\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nroc_auc = roc_auc_score(y_val, y_pred)\nf1score = f1_score(y_val, y_pred)\nconf_matrix = confusion_matrix(y_val, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\nprint(f\"F1 Score: {f1score:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\nfrom sklearn.svm import SVC\nmodel = SVC(kernel='rbf', C=10, gamma=0.1, coef0=0.0)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nroc_auc = roc_auc_score(y_val, y_pred)\nf1score = f1_score(y_val, y_pred)\nconf_matrix = confusion_matrix(y_val, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\nprint(f\"F1 Score: {f1score:.4f}\")\nprint(\"Confusion Matrix:\")\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, max_depth=30, min_samples_split=2, min_samples_leaf=1, max_features='sqrt')\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nroc_auc = roc_auc_score(y_val, y_pred)\nf1score = f1_score(y_val, y_pred)\nconf_matrix = confusion_matrix(y_val, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\nprint(f\"F1 Score: {f1score:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(conf_matrix)\n\n\n\nrf=RandomForestClassifier(n_estimators=100, max_depth=30, min_samples_split=2, min_samples_leaf=1, max_features='sqrt',oob_score=True, random_state=42)\nrf.fit(X_scaled, y_res)\n\n\ntest_df.info()test_df.info()\n\n\ntest_ids = test_df['id']\ntest_df.drop(['id','CustomerId','Surname'],axis=1,inplace=True)\n\n\ntest_df.duplicated().sum()\n\nX_res.info()\n\n\ndf_encoded = pd.get_dummies(test_df, columns=['Gender', 'Geography'], drop_first=True, dtype=int)\n\n\nX_test=df_encoded\nX_test.info()\ndf_encoded.info()\nX_test_scaled = scaler.transform(X_test)\ny_pred=rf.predict_proba(X_test_scaled)\n\n\n\nsub_df = pd.DataFrame({\n    'id': test_ids,\n    'Exited': y_pred[:,1]\n})\nsub_df.to_csv('submission_Bank.csv', index=False,float_format='%.6f')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}